{"metadata":{"jupytext":{"formats":"ipynb,py:light"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <font style=\"color:blue\">Faster RCNN Fine-tuning Experiment</font>\n\nJiž známe následující stavební blokové schéma Faster RCNN.\n\n---\n![](https://www.researchgate.net/profile/Giang_Son_Tran/publication/324549019/figure/fig1/AS:649929152266241@1531966593689/Faster-R-CNN-Architecture-9.png)\n\n---\n\nChceme rychle doladit model Faster RCNN, aby fungoval pro náš detekční problém.\nPoslední vrstva (klasifikátor) ve výše uvedeném obrázku bere zvětšené vlastnosti všech navrhovaných ohraničujících boxů a předpovídá třídy a ohraničující boxy. Pro tento úkol používá síť FastRCNNPredictor. Takže pro doladění s našimi daty musíme aktualizovat počet tříd v prediktoru.\n\nAbychom získali model Faster RCNN s požadovaným počtem tříd, můžeme napsat následující metodu.\n\n```python\ndef faster_rcnn_pretrained_model(num_classes):\n    # load an instance detection model pre-trained on COCO\n    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n\n    # get the number of input features for the classifier\n    in_features = model.roi_heads.box_predictor.cls_score.in_features\n    # replace the pre-trained head with a new one\n    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n    \n    return model\n```\n\nZačněme trénovat. Trainer použijeme k trénování a vyhodnocování našeho modelu. \n","metadata":{}},{"cell_type":"code","source":"!wget \"https://raw.githubusercontent.com/RadimKozl/OpenCV_academy_my_work/refs/heads/main/work_module/trainer_faster_rcnn.zip\" -O ./trainer.zip\n\n!ls /kaggle/working/\n\n!unzip /kaggle/working/trainer.zip\n\n!rm /kaggle/working/trainer.zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget \"https://raw.githubusercontent.com/RadimKozl/OpenCV_academy_my_work/refs/heads/main/work_module/faster_rcnn_detector.py\" -O ./faster_rcnn_detector.py\n!wget \"https://raw.githubusercontent.com/RadimKozl/OpenCV_academy_my_work/refs/heads/main/work_module/__init__.py\" -O ./__init__.py","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <font style=\"color:blue\">Experiment (Trénink)</font>\n\nPojďme napsat třídu experimentu pro rychlé jemné doladění RCNN.","metadata":{}},{"cell_type":"code","source":"%matplotlib notebook\n%load_ext autoreload\n%autoreload 2\n\nimport os\nimport random\nimport cv2\n\nfrom operator import itemgetter\n\nimport numpy as np\nimport torch\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\n\nfrom torch.utils.data import DataLoader\nfrom torch.optim.lr_scheduler import MultiStepLR\n\nfrom trainer import Trainer, hooks, configuration\nfrom trainer.utils import patch_configs\nfrom trainer.utils import setup_system\n\nfrom trainer.metrics import APEstimator\nfrom trainer.datasets import ListDataset\nfrom trainer.matplotlib_visualizer import MatplotlibVisualizer\nfrom trainer.utils import collate_fn\n\nfrom faster_rcnn_detector import faster_rcnn_pretrained_model\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">1. Třída Experiment</font>","metadata":{}},{"cell_type":"code","source":"class Experiment:\n    def __init__(\n        self,\n        system_config: configuration.SystemConfig = configuration.SystemConfig(),\n        dataset_config: configuration.DatasetConfig = configuration.DatasetConfig(),  \n        dataloader_config: configuration.DataloaderConfig = configuration.DataloaderConfig(),\n        optimizer_config: configuration.OptimizerConfig = configuration.OptimizerConfig(),\n    ):\n        self.system_config = system_config\n        setup_system(system_config)\n        \n        # fruit detection data has 3-classes. Anything other than these three classes is called background\n        self.classes = ['__background__', 'apple', 'banana', 'orange']\n        \n        # written custom dataset class of our dataset\n        train_csv_path = os.path.join(dataset_config.root_dir, 'labels_train.csv')\n        self.dataset_train = ListDataset(\n            csv_path=train_csv_path,\n            train = True,\n            transform=None\n        )\n\n        self.loader_train = DataLoader(\n            dataset=self.dataset_train,\n            batch_size=dataloader_config.batch_size,\n            shuffle=True,\n            collate_fn=collate_fn,\n            num_workers=dataloader_config.num_workers,\n            pin_memory=True\n        )\n        \n        test_csv_path = os.path.join(dataset_config.root_dir, 'labels_test.csv')\n\n        self.dataset_test = ListDataset(\n            csv_path=test_csv_path,\n            train=False,\n            transform=None\n        )\n        self.loader_test = DataLoader(\n            dataset=self.dataset_test,\n            batch_size=dataloader_config.batch_size,\n            shuffle=False,\n            collate_fn=collate_fn,\n            num_workers=dataloader_config.num_workers,\n            pin_memory=True\n        )\n        \n        # get faster rcnn model pretrained on coco\n        self.model = faster_rcnn_pretrained_model(len(self.classes))\n        \n        self.metric_fn = APEstimator(classes=self.classes)\n        \n        params = [p for p in self.model.parameters() if p.requires_grad]\n        self.optimizer = optim.SGD(\n            params,\n            lr=optimizer_config.learning_rate,\n            weight_decay=optimizer_config.weight_decay,\n            momentum=optimizer_config.momentum\n        )\n        self.lr_scheduler = MultiStepLR(\n            self.optimizer, milestones=optimizer_config.lr_step_milestones, gamma=optimizer_config.lr_gamma\n        )\n        self.visualizer = MatplotlibVisualizer()\n\n    def run(self, trainer_config: configuration.TrainerConfig) -> dict:  \n        setup_system(self.system_config)\n        device = torch.device(trainer_config.device)\n        self.model = self.model.to(device)\n\n        model_trainer = Trainer(\n            model=self.model,\n            loader_train=self.loader_train,\n            loader_test=self.loader_test,\n            metric_fn=self.metric_fn,\n            optimizer=self.optimizer,\n            lr_scheduler=self.lr_scheduler,\n            device=device,\n            data_getter=itemgetter(\"image\"),\n            target_getter=itemgetter(\"target\"),\n            stage_progress=trainer_config.progress_bar,\n            get_key_metric=itemgetter(\"mAP\"),\n            visualizer=self.visualizer,\n            model_save_best=trainer_config.model_save_best,\n            model_saving_frequency=trainer_config.model_saving_frequency,\n            save_dir=trainer_config.model_dir\n        )\n\n        model_trainer.register_hook(\"train\", hooks.train_hook_faster_rcnn)\n        model_trainer.register_hook(\"test\", hooks.test_hook_faster_rcnn)\n        model_trainer.register_hook(\"end_epoch\", hooks.end_epoch_hook_faster_rcnn)\n        self.metrics = model_trainer.fit(trainer_config.epoch_num)\n        return self.metrics\n\n    def draw_bboxes(self, rows, columns, trainer_config: configuration.TrainerConfig):\n        # load the best model\n        if trainer_config.model_save_best:\n            self.model.load_state_dict(\n                torch.\n                load(os.path.join(trainer_config.model_dir, self.model.__class__.__name__) + '_best.pth')\n            )\n        # or use the last saved\n        self.model = self.model.eval()\n\n        fig, ax = plt.subplots(\n            nrows=rows, ncols=columns, figsize=(15, 30), gridspec_kw={\n                'wspace': 0,\n                'hspace': 0.05\n            }\n        )\n        \n        colors = [(255, 0, 0), (0, 225, 0), (0, 0, 225)]\n\n        for axi in ax.flat:\n            index = random.randrange(len(self.loader_test.dataset))\n\n            image, targets = self.loader_test.dataset[index]\n\n            device = torch.device(trainer_config.device)\n            image = image.to(device).clone()\n\n            detections = self.model(image.unsqueeze(0))\n            bboxes = detections[0]['boxes'].cpu().detach().numpy()\n            labels = detections[0]['labels'].cpu().detach().numpy()\n            scores = detections[0]['scores'].cpu().detach().numpy()\n\n            with torch.no_grad():\n                img = image.cpu()\n                img = img.numpy().transpose(1, 2, 0)\n                img = (img * 255.).astype(np.uint8)\n                gt_img = img.copy()\n                pred_img = img.copy()\n\n                for i, box in enumerate(targets['boxes']):\n                    label = targets['labels'][i]\n                    cls = self.classes[label]\n                    clr = colors[label-1]\n                    gt_img = cv2.rectangle(\n                        gt_img, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), clr, thickness=2)\n                    gt_img = cv2.putText(gt_img, cls, (int(box[0]), int(box[1])-10), cv2.FONT_HERSHEY_SIMPLEX, \n                                         0.9, clr, 2)\n                    \n                for i, box in enumerate(bboxes):\n                    label = labels[i]\n                    score = scores[i]\n                    cls = self.classes[label]\n                    clr = colors[label-1]\n                    cls_score = '{0}:{1:.2}'.format(cls, score)\n                    pred_img = cv2.rectangle(\n                        pred_img, (int(box[0]), int(box[1])), (int(box[2]), int(box[3])), clr, thickness=2)\n                    pred_img = cv2.putText(pred_img, cls_score, (int(box[0]), int(box[1])-10), \n                                           cv2.FONT_HERSHEY_SIMPLEX, 0.9, clr, 2)\n\n                merged_img = np.concatenate((gt_img, pred_img), axis=1)\n                axi.imshow(merged_img)\n                axi.axis('off')\n        fig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">2. Obrázky ovoce pro datovou sadu pro detekci objektů</font>\n\nZde jsme převzali datovou sadu pro detekci ovoce [Kaggle](https://www.kaggle.com/mbkinaci/fruit-images-for-object-detection). Má štítky ve formátu XML. Přidali jsme soubory štítků ve formátu CSV. Data si můžete stáhnout z **[tady](https://www.dropbox.com/sh/r2qxsaeq1otrtag/AAC1oI4g6n-upAB8M-VNYs68a?dl=1)**. \n\nSkládá se z `300` snímků (vlak `240` a testovací `60` ).\n\nMá tři třídy – jablko, banán a pomeranč. \n\nZde je jeden z příkladů dat, která datová sada poskytuje:\n\n### [Stáhnout data](https://www.dropbox.com/sh/r2qxsaeq1otrtag/AAC1oI4g6n-upAB8M-VNYs68a?dl=1)\n---\n\n<img src='https://www.dropbox.com/s/837sdq5d1f2jxz3/apple_3.jpg?dl=1' align='middle'>\n\n---\n","metadata":{}},{"cell_type":"markdown","source":"## <font style=\"color:green\">3. Spustit Experiment</font>","metadata":{}},{"cell_type":"code","source":"if __name__ == '__main__':\n    dataloader_config, trainer_config = patch_configs(epoch_num_to_set=100, batch_size_to_set=2)\n\n    dataset_config = configuration.DatasetConfig(\n        root_dir=\"/kaggle/input/opencv-fruit-images-for-object-detection\",\n    )\n    \n    optimizer_config = configuration.OptimizerConfig(\n        learning_rate=5e-3, \n        lr_step_milestones=[50], \n        lr_gamma=0.1, \n        momentum=0.9, \n        weight_decay=1e-5\n    )\n    \n    experiment = Experiment(\n        dataset_config=dataset_config, \n        dataloader_config=dataloader_config, \n        optimizer_config=optimizer_config\n    )\n    \n    # Run the experiment / start training\n    experiment.run(trainer_config)","metadata":{"lines_to_next_cell":2},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# how good our detector works by visualizing the results on the randomly chosen test images:\n\nif __name__ == '__main__':\n    experiment.draw_bboxes(4, 1, trainer_config)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font style=\"color:green\">4. Zkuste to s jinou datovou sadou</font>\n\nVylaďte model Faster-RCNN pro své vlastní nebo veřejně dostupné datové sady. Následuje několik odkazů na veřejně dostupné datové sady:\n\n- [MCIndoor20000](https://github.com/bircatmcri/MCIndoor20000)\n\n- [The Oxford-IIIT Pet Dataset](http://www.robots.ox.ac.uk/~vgg/data/pets/)\n\n- [PASCAL VOC](http://host.robots.ox.ac.uk/pascal/VOC/)\n\n- [KITTI Vision](http://www.cvlibs.net/datasets/kitti/)\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}